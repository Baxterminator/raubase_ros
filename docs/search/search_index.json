{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the Raubase-ROS package documentation","text":"<p>This website hosts the documentation about the package raubase_ros, a translation from the DTU Raubase software.</p> <p>The original author of the code is Jens Christan Andersen, and the ROS2 conversion was made by Geoffrey C\u00f4te (aka Meltwin online).</p> <p>This project is distributed under the MIT license. Copyright \u00a9 2017 -2024 by DTU </p>"},{"location":"#maintainer","title":"Maintainer","text":"<p>This package is maintained by:</p> <ul> <li>Geoffrey C\u00f4te ECN (General Engineering - Robotics) &amp; DTU (MSc Autonomous Sytem) student </li> <li>Jens Christan Andersen Associate professor in the Department of Electrical and Photonics Engineering (Automation and control)</li> </ul>"},{"location":"#dependencies","title":"Dependencies","text":"<p>This projects runs on: </p> <ul> <li>ROS: ROS2 Humble,       </li> <li>Python: 3.10</li> <li>OS: Ubuntu 22.04,</li> <li>Arch: Tested Raspberry Pi 4 and x86 computer,</li> </ul> Package Link Description rclcpp ROS2 Standard ROS ament_cmake ROS2 Standard Compilation Toolchain std_msgs ROS2 Standard ROS sensor_msgs ROS2 Standard Messages OpenCV OpenCV website Camera handling cv_bridge Vision OpenCV Github OpenCV - ROS bridge raubase_msgs Baxterminator - RobotBot MSG Github Custom messages"},{"location":"tools/","title":"Using the tools","text":"<p>This package aims to provide a back-end for simplifying the creation of tasks, especially for people not knowing ROS.  It implements wrappers over the ROS framework to give an high-level interface over the whole Raubase system.</p>"},{"location":"installation/intro/","title":"Raubase_ROS installation","text":"<p>This category will gather all tutorials about installation. You can find below the list of steps you'll have to do.</p> <ol> <li>(ROBOT ONLY) OS preparation</li> <li>Installation of the packages</li> <li>Setup discovery server for ROS2 communication between devices in multicast restricted environnement.</li> </ol>"},{"location":"installation/multicast/","title":"Multicast server for ROS2 in DTU","text":"<p>As stated in the goals of the project, one of the goal was to enable Cloud Computing with the robot. This means that you need to communicate between the robot and your computer. However, DTU routers configurations prevent the usage of the default communication protocols for ROS2. On this page, you will the informations you need on what problem arise will using ROS2 in DTU network, and how to fix it.</p>"},{"location":"installation/multicast/#the-problem-ros2-discovery-protocol","title":"The problem: ROS2 discovery protocol","text":"<p>If you try to make two computers running ROS2 communicate over the DTU network you will quickly see that they do not see each others. On the other side, ROS1 projects are running very well without any specific configurations. Why? The problem comes from how nodes are discovered in both versions.</p> <p>In ROS1, you have a master (i.e. a broker) that will centralized the dynamic sharing of information on every DDS participant. In this case, you configure the IP of the master on each device that will participate, so the communication only work on unicast (i.e. sending information from one device to one another). As this communication method does not rely on anything from the router point of view (except from redirecting the message to the IP), it works fine on the DTU network.</p> <p>ROS2 on the other hand choose to use a decentralized discovery protocol, thus there is no fixed \"master\" to redistribute the data. In fact, ROS2 rely on multicast (i.e. one device sending a message to all devices on a network using a gateway). However, this method is blocked inside of the DTU Network. </p>"},{"location":"installation/multicast/#how-to-solve-this-problem","title":"How to solve this problem ?","text":"<p>The solution is in fact really trivial, we just have to go back to the idea of ROS1: having a broker for discovery. I will here describe the method for the FastDDS RMW, but others RMW may have similar options.</p> <p>We will split between the server and the clients, but it's the same thing, except for the IP that you'll have to enter. You find references about the setup on the FastDDS wiki <sup>1</sup> and on this Medium article<sup>2</sup>. </p>"},{"location":"installation/multicast/#on-the-server-host-typically-the-robot","title":"On the server host (typically the robot)","text":"<p>On the host, create a file <code>fastdds_conf.xml</code><sup>3</sup> somewhere, and put the contents of this file inside. <pre><code>curl https://fast-dds.docs.eprosima.com/en/latest/_downloads/9f9e92b14612364b742c8ecde24b3d24/super_client_configuration_file.xml &gt; fast_dds.conf\n</code></pre></p> <p>Now, you can add the following lines in your .bashrc (or .zshrc if you use zsh):</p> <pre><code>export RMW_IMPLEMENTATION=rmw_fastrtps_cpp\nexport FASTRTPS_DEFAULT_PROFILES_FILE=/path_to_your_file/fastdds_conf.xml\nexport ROS_DISCOVERY_SERVER=127.0.0.1:11811\n</code></pre> <p>Finally to apply the changes, you just have to restart the ros2 daemon to apply to changes:</p> <pre><code>ros2 daemon stop\nros2 daemon start\n</code></pre>"},{"location":"installation/multicast/#on-the-clients-side","title":"On the clients side","text":"<p>For the clients, the processus is a bit the same as for the server. However, for the server we used the loopback IP (127.0.0.1), and thus won't work for the client. The first thing you have to do is to get the server IP:</p> Run this on the robot<pre><code>ifconfig\n</code></pre> <p>You will then have a result like this:</p> <pre><code>lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536\n        inet 127.0.0.1  netmask 255.0.0.0\n        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;\n        loop  txqueuelen 1000  (Local Loopback)\n        RX packets 432746  bytes 178993688 (178.9 MB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 432746  bytes 178993688 (178.9 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nwlp0s20f3: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500\n        inet 10.15.222.62  netmask 255.255.240.0  broadcast 10.15.223.255\n        inet6 fe80::289a:b1c0:5f05:dcf  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether ec:63:d7:fd:8a:fe  txqueuelen 1000  (Ethernet)\n        RX packets 8618102  bytes 10333207988 (10.3 GB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 1315555  bytes 343510087 (343.5 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n</code></pre> <p>The highlighted lines correspond to the wifi interface<sup>4</sup>. On the second line you can find the configuration if this interface (i.e. the IPV4 (<code>inet</code>), the network mask (<code>netmask</code>) and the broadcast address (<code>broadcat</code>)). Here, only the IPV4 will be of use in the next.</p> <p>Now, you will do pretty much the same things as for the server. Begin by making the <code>fastdds_conf.xml</code> file.</p> Run this on the client<pre><code>curl https://fast-dds.docs.eprosima.com/en/latest/_downloads/9f9e92b14612364b742c8ecde24b3d24/super_client_configuration_file.xml &gt; fast_dds.conf\n</code></pre> <p>But now you have to change the IP in this file. So instead of <code>127.0.0.1</code>, replace by the IP you got with the <code>ifconfig</code> previously.</p> Change this on the client<pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;\n&lt;dds&gt;\n    &lt;profiles xmlns=\"http://www.eprosima.com/XMLSchemas/fastRTPS_Profiles\"&gt;\n        &lt;participant profile_name=\"super_client_profile\" is_default_profile=\"true\"&gt;\n            &lt;rtps&gt;\n                &lt;builtin&gt;\n                    &lt;discovery_config&gt;\n                        &lt;discoveryProtocol&gt;SUPER_CLIENT&lt;/discoveryProtocol&gt;\n                        &lt;discoveryServersList&gt;\n                            &lt;RemoteServer prefix=\"44.53.00.5f.45.50.52.4f.53.49.4d.41\"&gt;\n                                &lt;metatrafficUnicastLocatorList&gt;\n                                    &lt;locator&gt;\n                                        &lt;udpv4&gt;\n                                            &lt;address&gt;put the robot IP here&lt;/address&gt;\n                                            &lt;port&gt;11811&lt;/port&gt;\n                                        &lt;/udpv4&gt;\n                                    &lt;/locator&gt;\n                                &lt;/metatrafficUnicastLocatorList&gt;\n                            &lt;/RemoteServer&gt;\n                        &lt;/discoveryServersList&gt;\n                    &lt;/discovery_config&gt;\n                &lt;/builtin&gt;\n            &lt;/rtps&gt;\n        &lt;/participant&gt;\n    &lt;/profiles&gt;\n&lt;/dds&gt;\n</code></pre> <p>Then, you can add this lines to your .bashrc (or .zshrc if you use zsh) and change the IP once again with the robot IP here:</p> Change this on the client<pre><code>export RMW_IMPLEMENTATION=rmw_fastrtps_cpp\nexport FASTRTPS_DEFAULT_PROFILES_FILE=/path_to_your_file/fastdds_conf.xml\nexport ROS_DISCOVERY_SERVER=&lt;put the robot ip here&gt;:11811\n</code></pre> <p>Finally, to apply the changes, run the following commands:</p> Run this on the client<pre><code>ros2 daemon stop\nros2 daemon start\n</code></pre> <ol> <li> <p>EProsima FastDDS - Use ROS 2 with Fast-DDS Discovery Server \u21a9</p> </li> <li> <p>RoboFoundy on Medium - How to setup ROS2 Fast-DDS Discovery Server \u21a9</p> </li> <li> <p>The name of the file can be anything, one was just decided for coherence through the page.\u00a0\u21a9</p> </li> <li> <p>Here the wifi interface's name is <code>wlp0s20f3</code>, but it can be anything else. However they will likely start with a \"w\", for \"wireless\".\u00a0\u21a9</p> </li> </ol>"},{"location":"installation/package/","title":"Raubase_ROS package installation","text":"<p>Warning</p> <p>Prior to any installation, make sure ROS2 Humble is installed on your computer and sourced in the terminal. </p> <p>To install ROS2 Humble, follow the official installation guides from the ROS2 Documentation.</p>"},{"location":"installation/package/#preparing-the-environnement","title":"Preparing the environnement","text":"<p>As any ROS package, you must first make a workspace to build the several packages that you will need.</p> <p>For that, create a directory wherever you want, and create a <code>src</code> folder inside.</p> <pre><code>mkdir dtu_ws/src\ncd dtu_ws/src\n</code></pre>"},{"location":"installation/package/#fetching-the-packages-and-dependencies","title":"Fetching the packages and dependencies","text":"<p>The next step is to install the packages and their dependencies from Github.</p> <pre><code>sudo apt update\nsudo apt install ros-humble-camera-calibration-parsers ros-humble-camera-info-manager ros-humble-launch-testing-ament-cmake\ngit clone git@github.com:ros-perception/image_pipeline.git -b humble\ngit clone git@github.com:ros-perception/vision_opencv.git -b humble\ngit clone git@github.com:Baxterminator/raubase_msgs.git\ngit clone git@github.com:Baxterminator/raubase_ros.git\n</code></pre>"},{"location":"installation/package/#optional-compile-only-necessary-packages","title":"(Optional) Compile only necessary packages","text":"<p>The two first repository in the list are meta-packages (i.e. repositories that gather several packages in one place so that you can compile everything together), and you don't really need everything. In fact the only packages that we really need are:</p> <ul> <li><code>vision_opencv/cv_bridge</code>: a ROS2 package that facilitate conversion between OpenCV image and ROS2 Image and CompressedImage messages,</li> <li><code>vision_opencv/image_geometry</code>: \"collection of methods for dealing with image and pixel geometry\"<sup>1</sup>. This package is needed by the <code>image_calibration</code> package.</li> <li><code>image_pipeline/image_calibration</code>: a tool to calibrate cameras in ROS2<sup>2</sup></li> </ul> <p>In the end, a lot of the <code>image_pipeline</code> packages are not really needed.</p> <pre><code>echo &gt; image_pipeline/COLCON_IGNORE\nmv image_pipeline/image_calibration image_calibration\n</code></pre>"},{"location":"installation/package/#building-everything","title":"Building everything","text":"<p>Now is the time to build everything:</p> <pre><code>cd ..\ncolcon build\n</code></pre>"},{"location":"installation/package/#sourcing-the-whole-stack","title":"Sourcing the whole stack","text":"<p>When everything is built, you can source the stack for further purposes. The method doesn't change from a regular ROS2 workspace, so you can rely on the ROS2 Documentation for this part. Nonetheless, we give here a reminder on how to do it:</p> <pre><code>source ./install/local_setup.sh\n</code></pre> <p>Info</p> <p>If you want to source automatically the workspace on startup, you can add the following line in your .bashrc / .zshrc</p> <pre><code>source \"/absolute_path_to_workspace/install/setup.sh\"\n</code></pre> <ol> <li> <p>Cf. the description made on the Vision_OpenCV Package Github \u21a9</p> </li> <li> <p>Installation instruction and usage of the calibration tool can be found on the Nav2 Wiki \u21a9</p> </li> </ol>"},{"location":"introduction/why/","title":"Why this project ?","text":"<p>During 2024, 9 intensive weeks of this course, I observed several things:</p> <ul> <li>A lot of people never touch a robot before and thus can be a bit lost while digging in the original code,</li> <li>Moreover, a lot do not know about C++ either, which make the discovery and understanding process even more complicated,</li> <li>The original code is working, but I felt the structure and data sharing a bit messy,</li> <li>If we wanted to add anything, we had to it from scratch and in C++,</li> <li>The Raspberry Pi, even if we have RPi 4 with 8GB, they are still limiting in computation power, autonomy (the robot on battery), lacks of GPU, ..., and it is not that easy to integrate a cloud computing solution of the already existing code without having to rewrite a whole communication part.</li> </ul> <p>For this reason, we decided to switch to ROS with a few goals in minds:</p> <ol> <li>Improved Backend<ol> <li>Robust: Make a more robust system by splitting the program in Node communicating between them with DDS.</li> <li>External Server Computing the DDS communication allow an easy Cloud Computing implementation,</li> <li>Python support using ROS put a new programming language in the balance - Python - that is a bit more known than C++.</li> </ol> </li> <li>Opening the door to every ROS2 available tools<ol> <li>Do not reinvent the wheel: a lot of things have already been done, especially about the navigation stack or even on sensor fusion, ... With a ROS2 integration, we open the door to all of these tools.</li> </ol> </li> <li>High-level User Friendly Interface <ol> <li>Easy to program: as everyone is not that equal in skills about programming, this interface should provide an easy task description and running.</li> <li>As simple as possible: even when adding Python in the balance, a lot of people doesn't know both languages that much. The interface should be as simple as possible so that everyone could write at least simple tasks.</li> <li>ROS agnostic: since ROS is not that well-known either, the interface should abstract all ROS works, at least for the simple tasks.</li> </ol> </li> </ol>"},{"location":"messages/data/","title":"Raubase Sensor Data Messages","text":"<p>This page registers the custom sensors data messages.</p>"},{"location":"messages/data/#raubase_msgsmsgdatadistance","title":"raubase_msgs::msg::DataDistance","text":"<p>This messages contains the raw value for one IR sensor.</p> IDLC++Python <pre><code># This message contains the data of one of the plugged sensor\nbuiltin_interfaces/Time stamp\n\nchar UNKNOWN = 0\nchar SHARP = 1\nchar URM09 = 2\n\nchar type 1\n\nfloat64[2] calib\nfloat64 range\nfloat64 range_ad\n</code></pre> <pre><code>struct DataDistance {\n  static constexpr const char UNKNOWN{0};\n  static constexpr const char SHARP{1};\n  static constexpr const char URM09{2};\n\n  builtin_interfaces::msg::Time stamp;\n  char type = SHARP;\n  double calib[2];\n  double range;\n  double range_ad; \n};\n</code></pre> <pre><code>class DataDistance:\n    UNKNOWN = 0\n    SHARP = 1\n    URM09 = 2\n\n    def __init__(self):\n        self.stamp : builtin_interfaces.msg.Time\n        self.type : int\n        self.calib : Tuple[float, float]\n        self.range : float\n        self.range_ad: float\n</code></pre>"},{"location":"messages/data/#raubase_msgsmsgdataencoder","title":"raubase_msgs::msg::DataEncoder","text":"<p>This messages contains both encoders position.</p> IDLC++Python <pre><code>builtin_interfaces/Time stamp\n\nint32 right\nint32 left\n</code></pre> <pre><code>struct DataEncoder {\n  builtin_interfaces::msg::Time stamp;\n  int right;\n  int left; \n};\n</code></pre> <pre><code>class DataEncoder:\n    def __init__(self):\n        self.stamp : builtin_interfaces.msg.Time\n        self.right : int\n        self.left  : int\n</code></pre>"},{"location":"messages/data/#raubase_msgsmsgdatalinesensor","title":"raubase_msgs::msg::DataLineSensor","text":"<p>This messages the raw reading from the line sensor.</p> IDLC++Python <pre><code>builtin_interfaces/Time stamp\n\n# Values of each sensor of the sensor line\nint32[] data\n</code></pre> <pre><code>struct DataLineSensor {\n  builtin_interfaces::msg::Time stamp;\n  std::vector&lt;int&gt; data;\n};\n</code></pre> <pre><code>class DataLineSensor:\n    def __init__(self):\n        self.stamp : builtin_interfaces.msg.Time\n        self.data : List[int]\n</code></pre>"},{"location":"messages/messages/","title":"Raubase ROS internal messages","text":"<p>The raubase_ros package use custom internal messages to process its own data. However, they are not present on the raubase_ros package but instead in the raubase_msgs package.</p> <p>You'll find here the definitions of the messages in separate pages, grouped by theme.</p>"},{"location":"messages/messages/#index-of-the-messages","title":"Index of the messages","text":""},{"location":"messages/messages/#actions","title":"Actions","text":""},{"location":"messages/messages/#messages","title":"Messages","text":"<ul> <li><code>raubase_msgs/DataDistance</code></li> <li><code>raubase_msgs/DataEncoder</code></li> <li><code>raubase_msgs/DataLineSensor</code></li> <li><code>raubase_msgs/ObjectArUco</code></li> <li><code>raubase_msgs/ObjectBall</code></li> <li><code>raubase_msgs/ObjectYolo</code></li> <li><code>raubase_msgs/ResultArUco</code></li> <li><code>raubase_msgs/ResultBall</code></li> <li><code>raubase_msgs/ResultYolo</code></li> <li><code>raubase_msgs/ResultEdge</code></li> <li><code>raubase_msgs/ResultOdometry</code></li> </ul>"},{"location":"messages/messages/#services","title":"Services","text":""},{"location":"messages/results/","title":"Raubase Algorithm Result Messages","text":"<p>This page registers the custom results from diverse algorithms.</p>"},{"location":"messages/results/#objects","title":"Objects","text":""},{"location":"messages/results/#raubase_msgsmsgobjectaruco","title":"raubase_msgs::msg::ObjectArUco","text":"<p>This messages contains the data from one ArUco code.</p> IDLC++Python <pre><code># ArUco object description\nstd_msgs/Header header\n\nint32 id\n\n# Corners in images\nfloat32[4] corners_x\nfloat32[4] corners_y\n\n# Real world position and the three axes of the the ArUco marker.\ngeometry_msgs/Point x\ngeometry_msgs/Vector3 rx\ngeometry_msgs/Vector3 ry\ngeometry_msgs/Vector3 rz\n</code></pre> <pre><code>struct ObjectArUco {\n  std_msgs::msg::Header header;\n  int id;\n\n  float corners_x[4];\n  float corners_y[4];\n\n  geometry_msgs::msg::Point x;\n  geometry_msgs::msg::Vector3 rx;\n  geometry_msgs::msg::Vector3 ry;\n  geometry_msgs::msg::Vector3 rz;\n};\n</code></pre> <pre><code>class ObjectArUco:\n    def __init__(self):\n        self.header : std_msgs.msg.Header\n        self.id : int\n        self.corners_x : List[float]\n        self.corners_y : List[float]\n        self.x : geometry_msgs.msg.Point\n        self.rx, self.ry, self.rz: geometry_msgs.msg.Vector3\n</code></pre>"},{"location":"messages/results/#raubase_msgsmsgobjectball","title":"raubase_msgs::msg::ObjectBall","text":"<p>This messages contains the data from one detected ball.</p> IDLC++Python <pre><code># Ball object description\nstd_msgs/Header header\n\n# Position in image\nint32 x\nint32 y\nfloat64 r\n</code></pre> <pre><code>struct ObjectBall {\n  std_msgs::msg::Header header;\n  int x, y;\n  double r;\n};\n</code></pre> <pre><code>class ObjectBall:\n    def __init__(self):\n        self.header : std_msgs.msg.Header\n        self.x, self.y : int\n        self.r : float\n</code></pre>"},{"location":"messages/results/#raubase_msgsmsgobjectyolo","title":"raubase_msgs::msg::ObjectYolo","text":"<p>This messages contains the data from element of the YOLO classifier result.</p> IDLC++Python <pre><code># Yolo object descriptor\nstd_msgs/Header header\n\n# Position in image\nint32 xmin\nint32 xmax\nint32 ymin\nint32 ymax\n\n# Real world position (at center)\ngeometry_msgs/Point robot_x\n\nstring classifier\nfloat64 confidence\n</code></pre> <pre><code>struct ObjectYolo {\n  std_msgs::msg::Header header;\n\n  int xmin, xmax;\n  int ymin, ymax;\n\n  geometry_msgs::msg::Point robot_x;\n\n  std::string classifier;\n  double confidence;\n};\n</code></pre> <pre><code>class ObjectYolo:\n    def __init__(self):\n        self.header : std_msgs.msg.Header\n\n        self.xmin, self.xmax : int\n        self.ymin, self.ymax : int\n\n        self.robot_x : geometry_msgs.msg.Point\n\n        self.classifier : str\n        self.confidence : float\n</code></pre>"},{"location":"messages/results/#results","title":"Results","text":""},{"location":"messages/results/#raubase_msgsmsgresultaruco","title":"raubase_msgs::msg::ResultArUco","text":"<p>This messages contains the gathered data from the ArUco code analysis.</p> IDLC++Python <pre><code>ObjectArUco[] detected\n</code></pre> <pre><code>struct ResultArUco {\n    std::vecor&lt;raubase_msgs::msg::ObjectArUco&gt; detected;\n};\n</code></pre> <pre><code>class ResultArUco:\n    def __init__(self):\n        self.detected : List[raubase_msgs.msg.ObjectArUco]\n</code></pre>"},{"location":"messages/results/#raubase_msgsmsgresultball","title":"raubase_msgs::msg::ResultBall","text":"<p>This messages contains the gathered data from the ball algorithm.</p> IDLC++Python <pre><code>ObjectBall[] detected\n</code></pre> <pre><code>struct ResultBall {\n    std::vecor&lt;raubase_msgs::msg::ObjectBall&gt; detected;\n};\n</code></pre> <pre><code>class ResultBall:\n    def __init__(self):\n        self.detected : List[raubase_msgs.msg.ObjectBall]\n</code></pre>"},{"location":"messages/results/#raubase_msgsmsgresultyolo","title":"raubase_msgs::msg::ResultYolo","text":"<p>This messages contains the gathered data from the YOLO classifier algorithm.</p> IDLC++Python <pre><code>ObjectYolo[] detected\n</code></pre> <pre><code>struct ResultYolo {\n    std::vecor&lt;raubase_msgs::msg::ObjectYolo&gt; detected;\n};\n</code></pre> <pre><code>class ResultYolo:\n    def __init__(self):\n        self.detected : List[raubase_msgs.msg.ObjectYolo]\n</code></pre>"},{"location":"messages/results/#raubase_msgsmsgresultedge","title":"raubase_msgs::msg::ResultEdge","text":"<p>This messages contains the result of the line edge detection.</p> IDLC++Python <pre><code>bool valid_edge  # If the edge is valid (i.e. it exists)\n\n# Distances to both edges (in m)\nfloat32 left_edge  \nfloat32 right_edge\n\n# Width of the line (in m)\nfloat32 width\n</code></pre> <pre><code>struct ResultEdge {\n    bool valid_edge;\n    float left_edge, right_edge;\n    float width;\n};\n</code></pre> <pre><code>class ResultEdge:\n    def __init__(self):\n        self.valid_edge : bool\n        self.left_edge : float\n        self.right_edge : float\n        self.width : float\n</code></pre>"},{"location":"messages/results/#raubase_msgsmsgresultodometry","title":"raubase_msgs::msg::ResultOdometry","text":"<p>This messages contains the result of the odometry algorithm.</p> IDLC++Python <pre><code># This message describe several odometry result of the robot\nbuiltin_interfaces/Time stamp\n\n# Left and right wheel velocities (in m/s)\nfloat64 v_right \nfloat64 v_left\n\nfloat64 v_lin     # Linear velocity of the robot\nfloat64 turn_rate # Angular velocity of the robot\n\n# World position\nfloat64 x\nfloat64 y\nfloat64 heading\n</code></pre> <pre><code>struct ResultOdometry {\n    builtin_interfaces::msg::Time stamp;\n\n    double v_right, v_left;\n    double v_lin, turn_rate;\n\n    double x, y, heading;\n};\n</code></pre> <pre><code>class ResultOdometry:\n    def __init__(self):\n        self.stamp : builtin_interfaces.msg.Time\n        self.v_right : float\n        self.v_left : float\n        self.v_lin : float\n        self.turn_rate : float\n        self.x, self.y : float\n        self.heading : float\n</code></pre>"},{"location":"python_api/conditions/","title":"Task conditions","text":"<p>You will find here a complete list of the conditions that you can use for your tasks. </p> <p>The implementation of these conditions can be found in the file <code>raubase_ros/plan/conditions.py</code> in the package.</p>"},{"location":"python_api/conditions/#interfaces","title":"Interfaces","text":"<p>All of the conditions inherits from a common interface TaskCondition:</p> <pre><code>class TaskCondition:\n    def test(self) -&gt; bool\n</code></pre> <p>But since some conditions could be only made starting a task or stopping a task, two other interfaces have been added to organize them:</p> <pre><code>class StartTaskCondition(TaskCondition):\n    pass\n</code></pre> <pre><code>class StopTaskCondition(TaskCondition):\n    pass\n</code></pre> <p>Warning</p> <p>These three interfaces should not be used in tasks condition, they only provide a solid baseline for all others ones.</p> <p>Info</p> <p>If you want to implement you own conditions, you can make one extending from one the three interface, depending of the needs.</p>"},{"location":"python_api/conditions/#general-purpose-conditions","title":"General purpose conditions:","text":""},{"location":"python_api/conditions/#never","title":"Never","text":"<pre><code>class Never(TaskCondition)\n</code></pre> <p>This condition prevent any start or stop, depending on where it is used. This condition can be useful in cases where you want a continous sub routine when couple with a Parallel task.</p>"},{"location":"python_api/conditions/#and-and-or-conditions","title":"AND and OR conditions","text":"<pre><code>class ANDConditions(TaskCondition):\n    def __init__(self, List[TaskCondition]) -&gt; None\n\nclass ORConditions(TaskCondition):\n    def __init__(self, List[TaskCondition]) -&gt; None\n</code></pre> <p>This two conditions are meta-conditions providing a way to use several conditions at once. Obviously we have:</p> <ul> <li>AND condition: all condition should be evaluated as True to be True</li> <li>OR condition: if one of the condition is fulfilled, then evaluate to True</li> </ul> <p>An example of how they can be used: </p> <pre><code>    ...\n    def start_conditions(self) -&gt; StartConditions:\n        return ANDConditions([\n            ConditionA(),\n            ConditionB(),\n            ...\n        ])\n    ...\n</code></pre>"},{"location":"python_api/conditions/#start-conditions-specifics","title":"Start conditions specifics","text":""},{"location":"python_api/conditions/#follow-previous-task","title":"Follow previous task","text":"<pre><code>class FollowPreviousTask(StartTaskCondition):\n</code></pre> <p>This condition will always launch the task when asked. Basically, it's always True. It's the opposite of the Never condition.</p>"},{"location":"python_api/conditions/#stop-conditions-specifics","title":"Stop conditions specifics","text":""},{"location":"python_api/conditions/#as-soon-as-possible","title":"As soon as possible","text":"<pre><code>class AsSoonAsPossible(StopTaskCondition):\n</code></pre> <p>This condition will make the plan stop as soon as possible. In the end it will make the task run only time.</p>"},{"location":"python_api/requirements/","title":"Task requirements","text":"<p>You will find here a complete list of the requirement that you can use for your tasks. All the requirements are contained in one enumeration Requirements which inherits from the BaseRequirement interface.</p> <p>The implementation of these conditions can be found in the file <code>raubase_ros/plan/data/requirements.py</code> in the package.</p> <p>You can combine the requirements with the integer (+) operator, or the binary (|)  or operator. </p>"},{"location":"python_api/requirements/#available-requirements","title":"Available requirements","text":""},{"location":"python_api/requirements/#requirementnone","title":"<code>Requirement.NONE</code>","text":"<p>This value is the default value meaning nothing. If your task doesn't need anything, this is what she should return.</p>"},{"location":"python_api/requirements/#requirementencoders","title":"<code>Requirement.ENCODERS</code>","text":"<p>This requirement ask for the encoders data to be available.</p>"},{"location":"python_api/requirements/#requirementdistance","title":"<code>Requirement.DISTANCE</code>","text":"<p>This ask for the availability of the IR distance sensors.</p>"},{"location":"python_api/requirements/#requirementodometry","title":"<code>Requirement.ODOMETRY</code>","text":"<p>Ask for the odometry results of the raubase software.</p>"},{"location":"python_api/requirements/#requirementcamera","title":"<code>Requirement.CAMERA</code>","text":"<p>Ask for grabbing the camera images and information (matrix, ...).</p>"},{"location":"python_api/requirements/#requirementyolo","title":"<code>Requirement.YOLO</code>","text":"<p>Ask for the result of the YOLO-base image classifier.</p>"},{"location":"python_api/requirements/#requirementaruco","title":"<code>Requirement.ARUCO</code>","text":"<p>Ask for the result of the ArUco code lector.</p>"},{"location":"python_api/requirements/#requirementmove","title":"<code>Requirement.MOVE</code>","text":"<p>Ask for move functions to be initialized.</p>"},{"location":"python_api/requirements/#requirementline","title":"<code>Requirement.LINE</code>","text":"<p>Ask for the function to follow the line to be initialized.</p>"},{"location":"python_api/requirements/#implementing-new-requirements","title":"Implementing new requirements","text":"<p>If you want to implement you own requirement, you can make a new class inheriting the BaseRequirement interface. You can define the enumeration value by calling the <code>BaseRequirement.next</code> method which implement a global counter to make each requirement unique. If you do not use this method, you will live with the risk of getting override by another requirement.</p> <pre><code>class MyRequirement(BaseRequirement):\n    Requirement_A = BaseRequirement.next()\n    Requirement_B = BaseRequirement.next()\n    Requirement_C = BaseRequirement.next()\n</code></pre>"},{"location":"python_api/shared_cmd/","title":"Task shared controls","text":"<p>You have at you disposal several commands interacting with different part of the Raubase software. Each one of them may be needing a requirement to be available.</p> <p>The data are gathered inside the structure ControlWrapper (can be found in the file <code>raubase_ros/plan/data/shared_control.py</code>) which is shared accross all tasks. On this page you can find all available commands. To use them, replace <code>ControlWrapper</code> by <code>self.control</code>.</p>"},{"location":"python_api/shared_cmd/#movement","title":"Movement","text":""},{"location":"python_api/shared_cmd/#controlwrapperset_vel_hvelocity-heading-none","title":"<code>ControlWrapper.set_vel_h(velocity, heading) -&gt; None</code>","text":"<p>Move the robot according to the given velocity and heading command.</p> <p>Requires: <code>Requirement.MOVE</code></p> <p>Params: </p> <ul> <li><code>float</code> velocity: the linear velocity command (in m/s)</li> <li><code>float</code> heading: the absolute heading the robot should have (in rad)</li> </ul>"},{"location":"python_api/shared_cmd/#controlwrapperset_vel_hvelocity-turn-rate-none","title":"<code>ControlWrapper.set_vel_h(velocity, turn rate) -&gt; None</code>","text":"<p>Move the robot according to the given velocity and turn rate command.</p> <p>Requires: <code>Requirement.MOVE</code></p> <p>Params: </p> <ul> <li><code>float</code> velocity: the linear velocity command (in m/s)</li> <li><code>float</code> turn rate: the turn rate to apply (in rad/s)</li> </ul>"},{"location":"python_api/shared_cmd/#controlwrapperfollow_lineegde-offset-none","title":"<code>ControlWrapper.follow_line(egde, offset) -&gt; None</code>","text":"<p>Automatically follow the line, especially the defined edge. Apply an offset to the line center.</p> <p>Requires: <code>Requirement.LINE</code></p> <p>Params: </p> <ul> <li><code>bool</code> edge: if True, follow the right edge, follow the left edge otherwise</li> <li><code>float</code> offset: the offset at which to follow the line (in m)</li> </ul>"},{"location":"python_api/shared_cmd/#controlwrappercontroller_inputmode-force-none","title":"<code>ControlWrapper.controller_input(mode, force) -&gt; None</code>","text":"<p>Configure the mixer to use the given mode in input.</p> <p>Requires: <code>InternalRequirement.CONTROLLER</code> (needed by <code>Requirement.MOVE</code>)</p> <p>Params: </p> <ul> <li><code>str</code> mode: the name of the input the mixer has to switch to</li> <li><code>bool</code> force: should force for sending the message (prevent sending two time the same message one after another)</li> </ul>"},{"location":"python_api/shared_data/","title":"Task shared data","text":"<p>You have at you disposal several result and sensors data. Each one of them may be needing a requirement to be available.</p> <p>The data are gathered inside the structure SharedData (can be found in the file <code>raubase_ros/plan/data/shared_data.py</code>) which is shared accross all tasks. On this page you can find all available values. To use them, replace <code>SharedData</code> by <code>self.data</code>.</p>"},{"location":"python_api/shared_data/#sensors","title":"Sensors","text":""},{"location":"python_api/shared_data/#shareddataencoders","title":"<code>SharedData.encoders</code>","text":"<p>Type: <code>raubase_msgs/DataEncoder</code></p> <p>Requires: <code>Requirement.ENCODERS</code></p> <p>It contains the latest received encoders values.</p>"},{"location":"python_api/shared_data/#shareddatadistance","title":"<code>SharedData.distance</code>","text":"<p>Type: <code>Dict[int, raubase_msgs/DataDistance]</code></p> <p>Requires: <code>Requirement.DISTANCE</code></p> <p>It contains the latest received IR sensors values. Since there could be several installed IR sensors on the robot, the informations are store in a dict where the key id the index of the sensor.</p>"},{"location":"python_api/shared_data/#shareddatalast_img","title":"<code>SharedData.last_img</code>","text":"<p>Type: <code>sensor_msgs/CompressedImage</code></p> <p>Requires: <code>Requirement.CAMERA</code></p> <p>Contains the latest available image from the camera. Should be decrypted through the cv_bridge package to get a raw image.</p>"},{"location":"python_api/shared_data/#results","title":"Results","text":""},{"location":"python_api/shared_data/#shareddataodometry","title":"<code>SharedData.odometry</code>","text":"<p>Type: <code>raubase_msgs/ResultOdometry</code></p> <p>Requires: <code>Requirement.ODOMETRY</code></p> <p>Get the latest computed and received odometry.</p>"},{"location":"python_api/shared_data/#shareddatalast_yolo","title":"<code>SharedData.last_yolo</code>","text":"<p>Type: <code>raubase_msgs/ResultYolo</code></p> <p>Requires: <code>Requirement.YOLO</code></p> <p>Get the latest computed and received YOLO classification.</p>"},{"location":"python_api/shared_data/#shareddatalast_aruco","title":"<code>SharedData.last_aruco</code>","text":"<p>Type: <code>raubase_msgs/ResultOdometry</code></p> <p>Requires: <code>Requirement.ARUCO</code></p> <p>Get the latest computed and received the latest detected ArUco codes.</p>"},{"location":"python_api/shared_data/#special","title":"Special","text":""},{"location":"python_api/shared_data/#shareddatadistance_1","title":"<code>SharedData.distance</code>","text":"<p>Type: <code>float</code></p> <p>Requires: <code>Requirement.ODOMETRY</code></p> <p>Internal register computing the distance since the latest call of <code>SharedData.reset_distance()</code> method, or since the beginning of the task otherwise.</p>"},{"location":"python_api/shared_data/#shareddatatime_origin","title":"<code>SharedData.time_origin</code>","text":"<p>Type: <code>float</code></p> <p>Requires: <code>Requirement.NONE</code></p> <p>Origin of the time for computing duration. This register is reset at the beginning of the task and on call of the method <code>SharedData.reset_time()</code>.</p>"},{"location":"python_api/shared_data/#shareddatatime_elapsed","title":"<code>SharedData.time_elapsed</code>","text":"<p>Type: <code>float</code></p> <p>Requires: <code>Requirement.NONE</code></p> <p>Auto-incrementing time register since the time saved in <code>SharedData.time_origin</code>. This value we be reset on task beginning or on method call <code>SharedData.reset_time()</code>.</p>"},{"location":"python_api/shared_data/#shareddatatask_time","title":"<code>SharedData.task_time</code>","text":"<p>Type: <code>float</code></p> <p>Requires: <code>Requirement.NONE</code></p> <p>Auto-incrementing time register since the beginning of the task.</p>"},{"location":"python_api/shared_data/#methods","title":"Methods","text":""},{"location":"python_api/shared_data/#shareddatareset_distance-none","title":"<code>SharedData.reset_distance() -&gt; None</code>","text":"<p>This method reset the distance register to 0.</p>"},{"location":"python_api/shared_data/#shareddatareset_time-none","title":"<code>SharedData.reset_time() -&gt; None</code>","text":"<p>This method reset both <code>SharedData.time_origin</code> (to now) and <code>SharedData.time_elapsed</code> (to 0). Its aim is to measure actions time and do some conditions on them.</p>"},{"location":"tasks/task/","title":"Make a custom task","text":"<p>This package define a simple to implement tasks to be run by the behavior plan. Each task should be an anwser to a certain problem, and may yse a state machine for that. For example, in the Robocup, one task should be made for one challenge only. </p> <p>The base template for a task is the following:</p> <pre><code>from raubase_ros.plan import BaseTask\nfrom raubase_ros.plan.conditions import StartTaskCondition, StopTaskCondition\nfrom raubase_ros.plan.data import Requirement\n\nclass TestTask(BaseTask):\n    def __init__(self) -&gt; None:\n        super().__init__()\n\n    def requirements(self) -&gt; Requirement:\n        pass\n\n    def start_conditions(self) -&gt; StartTaskCondition:\n        pass\n\n    def stop_conditions(self) -&gt; StopTaskCondition:\n        pass\n\n    def loop(self) -&gt; None:\n        pass\n</code></pre> <p>A task is a new class that extends the BaseTask interface. Thus, it should implement some interface methods that will be explained in the following sections. However we can note that these methods are splitted in two categories:</p> <ul> <li>Declarative: provide informations on the requirements, as well as the start and stop condition,</li> <li>Working: provide the actual task computation excecuted at each plan update.</li> </ul>"},{"location":"tasks/task/#task-requirements","title":"Task requirements","text":"<p>One of the first things to declare is the requirements, i.e. what components the task will use (e.g. the camera, the ArUco results, the movement of the robot, ...). You can find a complete list of the available requirements here.</p> <p>For example, if you task need to read the distance sensors and move the robot accordingly, the methods would be filled like:</p> <pre><code>    ...\n    def requirements(self) -&gt; Requirement:\n        return Requirement.MOVE | Requirement.DISTANCE\n\n    ...\n</code></pre>"},{"location":"tasks/task/#start-and-stop-conditions","title":"Start and stop conditions","text":"<p>These two methods declare when to start and when to stop a task and go to the next one. Again, you can find a complete list of the possible conditions here. For example, if you want to start right after the previous task you can use the following method:</p> <pre><code>    ...\n    def start_conditions(self) -&gt; StartTaskCondition:\n        return FollowPreviousTask()\n    ...\n</code></pre>"},{"location":"tasks/task/#runtime-loop","title":"Runtime loop","text":""},{"location":"tasks/task/#structure-of-the-function","title":"Structure of the function","text":"<p>The function  <code>loop()</code> of the task will be called regularly by the behavior plan. It should then be written in the shape of a state or a stateless machine depending on the use-case. Implementing a simple state machine in Python is easy:</p> <pre><code>from enum import Enum, auto\n\nclass State(Enum):\n    STATE_1 = auto()\n    STATE_2 = auto()\n    STATE_3 = auto()\n    ...\n\ndef StateTask(BaseTask):\n    def __init__(self):\n        super().__init__()\n        self.state = State.STATE_1\n\n    ...\n\n    def loop():\n        match self.state:\n            case State.STATE_1:\n                # Do your state 1 action here\n\n                if c1():\n                    self.state = State.STATE_2\n            case State.STATE_2:\n                # Do your state 2 action here\n\n                if c2():\n                    self.state = State.STATE_3\n\n            ...\n</code></pre>"},{"location":"tasks/task/#functions-and-data-available","title":"Functions and data available","text":"<p>With the requirements, you declared functionnalities you wanted to have. We will now talk on how to use them. This is working with two categories:</p> <ul> <li>Shared Data, i.e. all results and sensors data available from the requirements of all tasks. These data can be accessed in the variable <code>self.data.&lt;data name&gt;</code>.</li> <li>Shared Control, i.e. methods you can use to communicate with some parts of the Raubase Software. These methods are gathered under the field <code>self.control.&lt;function name&gt;</code></li> </ul> <p>For example, if you want to read encoders values and then move, you can write:</p> <pre><code>    ...\n    def requirements(self) -&gt; Requirement:\n        # Need these requirement to work\n        return Requirement.ENCODER | Requirement.MOVE \n\n    ...\n    def loop(self) -&gt; None:\n        # Read right encoder data\n        right_encoder = self.data.encoders.right\n\n        # Move at 1 m/s straight ahead\n        self.control.move_v_w(1.0, 0.0)\n</code></pre> <p>You can find the available data here, and commands here.</p>"}]}